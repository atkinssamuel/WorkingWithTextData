{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as rqst\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting news data using RSS feeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is RSS?\n",
    "RSS stands for “really simple syndication” or, depending on who you ask, “rich site summary.” At its heart, RSS refers to simple text files with necessary, updated information — news pieces, articles, that sort of thing. That stripped-down content gets plugged into a feed reader, an interface that quickly converts the RSS text files into a stream of the latest updates from around the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries used\n",
    "- ### feedparser\n",
    "Universal Feed Parser is a Python module for downloading and parsing syndicated feeds.\n",
    "- ### urllib.request\n",
    "The urllib.request module defines functions and classes which help in opening URLs (mostly HTTP) in a complex world — basic and digest authentication, redirections, cookies and more.\n",
    "- ### BeautifulSoup\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are extracting metadata from four news websites' RSS feeds: **NY Times, FOX, CBC, BBC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NY Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **feedparser** to parse the RSS feed of NY Times news of arts section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_feed = feedparser.parse('https://rss.nytimes.com/services/xml/rss/nyt/Arts.xml')#feedparsing rss\n",
    "# ny_feed: dictionary containing metadata (title, date, link, author, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result of one article for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '‘Song Exploder’ and the Inexhaustible Hustle of Hrishikesh Hirway', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'https://rss.nytimes.com/services/xml/rss/nyt/Arts.xml', 'value': '‘Song Exploder’ and the Inexhaustible Hustle of Hrishikesh Hirway'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.nytimes.com/2020/11/03/arts/hrishikesh-hirway-song-exploder.html'}, {'href': 'https://www.nytimes.com/2020/11/03/arts/hrishikesh-hirway-song-exploder.html', 'rel': 'standout', 'type': 'text/html'}], 'link': 'https://www.nytimes.com/2020/11/03/arts/hrishikesh-hirway-song-exploder.html', 'id': 'https://www.nytimes.com/2020/11/03/arts/hrishikesh-hirway-song-exploder.html', 'guidislink': False, 'summary': 'The creator of several podcasts and a new television series is a popular investigator of the creative process. But his most personal case remains unsolved.', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'https://rss.nytimes.com/services/xml/rss/nyt/Arts.xml', 'value': 'The creator of several podcasts and a new television series is a popular investigator of the creative process. But his most personal case remains unsolved.'}, 'authors': [{'name': 'Reggie Ugwu'}], 'author': 'Reggie Ugwu', 'author_detail': {'name': 'Reggie Ugwu'}, 'published': 'Tue, 03 Nov 2020 16:50:28 +0000', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=16, tm_min=50, tm_sec=28, tm_wday=1, tm_yday=308, tm_isdst=0), 'tags': [{'term': 'Music', 'scheme': 'http://www.nytimes.com/namespaces/keywords/des', 'label': None}, {'term': 'Television', 'scheme': 'http://www.nytimes.com/namespaces/keywords/des', 'label': None}, {'term': 'Podcasts', 'scheme': 'http://www.nytimes.com/namespaces/keywords/des', 'label': None}, {'term': 'Content Type: Personal Profile', 'scheme': 'http://www.nytimes.com/namespaces/keywords/des', 'label': None}, {'term': 'Hirway, Hrishikesh (1979- )', 'scheme': 'http://www.nytimes.com/namespaces/keywords/nyt_per', 'label': None}, {'term': 'Song Exploder (TV Program)', 'scheme': 'http://www.nytimes.com/namespaces/keywords/nyt_ttl', 'label': None}, {'term': 'The West Wing Weekly (Radio Program)', 'scheme': 'http://www.nytimes.com/namespaces/keywords/nyt_ttl', 'label': None}, {'term': 'Partners (Radio Program)', 'scheme': 'http://www.nytimes.com/namespaces/keywords/nyt_ttl', 'label': None}, {'term': 'Home Cooking (Radio Program)', 'scheme': 'http://www.nytimes.com/namespaces/keywords/nyt_ttl', 'label': None}], 'media_content': [{'height': '151', 'medium': 'image', 'url': 'https://static01.nyt.com/images/2020/11/03/arts/03hirway1/03hirway1-moth.jpg', 'width': '151'}], 'media_credit': [{'content': 'Erik Carter for The New York Times'}], 'credit': 'Erik Carter for The New York Times', 'content': [{'type': 'text/plain', 'language': None, 'base': 'https://rss.nytimes.com/services/xml/rss/nyt/Arts.xml', 'value': 'Hrishkesh Hirway is an artist himself — in indie bands and as a composer for film and television — but is best known for his portfolio of podcasts, all of which circle the question of what it takes to make something in the world.'}]}\n"
     ]
    }
   ],
   "source": [
    "print(ny_feed['entries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each article in parsed results, save its title, date, link, author, and full text. To get the full text of the article, we use **BeautifulSoup** to parse the html from its link, and select tags with the class of its main body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting metadata\n",
    "titles = []\n",
    "dates = []\n",
    "links = []\n",
    "authors = []\n",
    "texts = []\n",
    "for article in ny_feed['entries']:\n",
    "    titles.append(article['title'])\n",
    "    dates.append(article['published'])\n",
    "    links.append(article['link'])\n",
    "    html = rqst.urlopen(article['link'])\n",
    "    bs = BeautifulSoup(html, features='html.parser')\n",
    "    targets = bs.select('.css-158dogj')\n",
    "    text = ''\n",
    "    for target in targets:\n",
    "        text += target.text\n",
    "        text += ' '\n",
    "    texts.append(text)\n",
    "    if 'author' in article:\n",
    "        authors.append(article['author'])\n",
    "    else:\n",
    "        authors.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframe is created by data saved previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe\n",
    "ny_data={\"title\": titles, \"date\": dates,\"link\": links, \"author\": authors, \"text\": texts}\n",
    "ny=pd.DataFrame(ny_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‘Song Exploder’ and the Inexhaustible Hustle o...</td>\n",
       "      <td>Tue, 03 Nov 2020 16:50:28 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/hrishi...</td>\n",
       "      <td>Reggie Ugwu</td>\n",
       "      <td>Making something new is like climbing a mounta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’m a Chess Expert. Here’s What ‘The Queen’s G...</td>\n",
       "      <td>Tue, 03 Nov 2020 17:09:24 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/televi...</td>\n",
       "      <td>Dylan Loeb McClain</td>\n",
       "      <td>This article contains spoilers for “The Queen’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When a Dance Collective Was Like a Rock Band</td>\n",
       "      <td>Tue, 03 Nov 2020 13:54:35 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/dance/...</td>\n",
       "      <td>Gia Kourlas</td>\n",
       "      <td>In 1970, the Grand Union came into being, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A ‘Wicked’ Challenge and Other Tough Questions...</td>\n",
       "      <td>Tue, 03 Nov 2020 17:41:32 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/theater/ben...</td>\n",
       "      <td>Ben Brantley</td>\n",
       "      <td>I’m 15 years old and here is my question: When...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ian Bostridge on Schubert’s Hidden Depths</td>\n",
       "      <td>Tue, 03 Nov 2020 13:00:08 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/music/...</td>\n",
       "      <td>Ian Bostridge</td>\n",
       "      <td>I first got to know the 20 songs of Franz Schu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  ‘Song Exploder’ and the Inexhaustible Hustle o...   \n",
       "1  I’m a Chess Expert. Here’s What ‘The Queen’s G...   \n",
       "2       When a Dance Collective Was Like a Rock Band   \n",
       "3  A ‘Wicked’ Challenge and Other Tough Questions...   \n",
       "4          Ian Bostridge on Schubert’s Hidden Depths   \n",
       "\n",
       "                              date  \\\n",
       "0  Tue, 03 Nov 2020 16:50:28 +0000   \n",
       "1  Tue, 03 Nov 2020 17:09:24 +0000   \n",
       "2  Tue, 03 Nov 2020 13:54:35 +0000   \n",
       "3  Tue, 03 Nov 2020 17:41:32 +0000   \n",
       "4  Tue, 03 Nov 2020 13:00:08 +0000   \n",
       "\n",
       "                                                link              author  \\\n",
       "0  https://www.nytimes.com/2020/11/03/arts/hrishi...         Reggie Ugwu   \n",
       "1  https://www.nytimes.com/2020/11/03/arts/televi...  Dylan Loeb McClain   \n",
       "2  https://www.nytimes.com/2020/11/03/arts/dance/...         Gia Kourlas   \n",
       "3  https://www.nytimes.com/2020/11/03/theater/ben...        Ben Brantley   \n",
       "4  https://www.nytimes.com/2020/11/03/arts/music/...       Ian Bostridge   \n",
       "\n",
       "                                                text  \n",
       "0  Making something new is like climbing a mounta...  \n",
       "1  This article contains spoilers for “The Queen’...  \n",
       "2  In 1970, the Grand Union came into being, and ...  \n",
       "3  I’m 15 years old and here is my question: When...  \n",
       "4  I first got to know the 20 songs of Franz Schu...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export results as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny.to_csv('./ny.csv', index=True)#export to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FOX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **feedparser** to parse the RSS feed of FOX latest news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_feed = feedparser.parse('http://feeds.foxnews.com/foxnews/latest')#feedparsing rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result of one article for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'https://www.foxnews.com/sports/no-10-wisconsin-cancels-game-with-purdue-due-to-outbreak', 'guidislink': True, 'link': 'https://www.foxnews.com/sports/no-10-wisconsin-cancels-game-with-purdue-due-to-outbreak', 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.foxnews.com/sports/no-10-wisconsin-cancels-game-with-purdue-due-to-outbreak'}], 'media_content': [{'url': 'https://static.foxnews.com/foxnews.com/content/uploads/2020/11/AP20298017028265.jpg', 'medium': 'image', 'isdefault': 'true'}, {'url': 'http://a57.foxnews.com60/60/AP20298017028265.jpg', 'medium': 'image', 'width': '60', 'height': '60'}], 'media_thumbnail': [{'url': 'http://a57.foxnews.com60/60/AP20298017028265.jpg', 'width': '60', 'height': '60'}], 'href': '', 'tags': [{'term': '058a6f4b-e018-5c86-a423-88463afda044', 'scheme': 'foxnews.com/metadata/dc.identifier', 'label': None}, {'term': 'fox-news/sports/ncaa', 'scheme': 'foxnews.com/taxonomy', 'label': None}, {'term': 'fox-news/sports/ncaa-fb', 'scheme': 'foxnews.com/taxonomy', 'label': None}, {'term': 'fox-news/sports/ncaa/wisconsin-badgers', 'scheme': 'foxnews.com/taxonomy', 'label': None}, {'term': 'fox-news/sports/ncaa/purdue-boilermakers', 'scheme': 'foxnews.com/taxonomy', 'label': None}, {'term': 'fnc', 'scheme': 'foxnews.com/metadata/prism.channel', 'label': None}, {'term': 'fnc/sports', 'scheme': 'foxnews.com/section-path', 'label': None}, {'term': 'article', 'scheme': 'foxnews.com/content-type', 'label': None}, {'term': 'Associated Press', 'scheme': 'foxnews.com/metadata/dc.source', 'label': None}, {'term': None, 'scheme': 'foxnews.com/dateline', 'label': None}], 'title': 'No. 10 Wisconsin cancels game with Purdue due to outbreak', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.foxnews.com/foxnews/latest', 'value': 'No. 10 Wisconsin cancels game with Purdue due to outbreak'}, 'summary': \"Wisconsin has canceled Saturday's home game against Purdue, the second straight game the 10th-ranked Badgers have called off as COVID-19 cases within their team continue to rise.\", 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.foxnews.com/foxnews/latest', 'value': \"Wisconsin has canceled Saturday's home game against Purdue, the second straight game the 10th-ranked Badgers have called off as COVID-19 cases within their team continue to rise.\"}, 'published': 'Tue, 03 Nov 2020 19:33:36 GMT', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=19, tm_min=33, tm_sec=36, tm_wday=1, tm_yday=308, tm_isdst=0)}\n"
     ]
    }
   ],
   "source": [
    "print(fox_feed['entries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each article in parsed results, save its title, date, link, author, and full text. To get the full text of the article, we use **BeautifulSoup** to parse the html from its link, and select tags with the class of its main body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting metadata\n",
    "titles2 = []\n",
    "dates2 = []\n",
    "links2 = []\n",
    "authors2 = []\n",
    "texts2 = []\n",
    "for article in fox_feed['entries']:\n",
    "    titles2.append(article['title'])\n",
    "    dates2.append(article['published'])\n",
    "    links2.append(article['link'])\n",
    "    html = rqst.urlopen(article['link'])\n",
    "    bs = BeautifulSoup(html, features='html.parser')\n",
    "    targets = bs.select('.article-body')[0].select('p')\n",
    "    text = ''\n",
    "    for target in targets:\n",
    "        text += target.text\n",
    "        text += ' '\n",
    "    texts2.append(text)\n",
    "    if 'author' in article:\n",
    "        authors2.append(article['author'])\n",
    "    else:\n",
    "        authors2.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframe is created by data saved previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No. 10 Wisconsin cancels game with Purdue due ...</td>\n",
       "      <td>Tue, 03 Nov 2020 19:33:36 GMT</td>\n",
       "      <td>https://www.foxnews.com/sports/no-10-wisconsin...</td>\n",
       "      <td>None</td>\n",
       "      <td>Fox News Flash top headlines are here. Check o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Election 2020: Live Coverage</td>\n",
       "      <td>Tue, 03 Nov 2020 19:30:59 GMT</td>\n",
       "      <td>https://www.foxnews.com/politics/election-2020...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beverly Hills spending $4.8M on 'election-prep...</td>\n",
       "      <td>Tue, 03 Nov 2020 19:23:52 GMT</td>\n",
       "      <td>https://www.foxnews.com/us/beverly-hills-rodeo...</td>\n",
       "      <td>Danielle Wallace</td>\n",
       "      <td>Roughly 2,100 voters in Los Angeles County rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFL to consider 16-team playoff structure for ...</td>\n",
       "      <td>Tue, 03 Nov 2020 19:22:29 GMT</td>\n",
       "      <td>https://www.foxnews.com/sports/nfl-16-team-pla...</td>\n",
       "      <td>Paulina Dedaj</td>\n",
       "      <td>Fox News Flash top headlines are here. Check o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colorado hiker with coronavirus-like symptoms ...</td>\n",
       "      <td>Tue, 03 Nov 2020 19:20:33 GMT</td>\n",
       "      <td>https://www.foxnews.com/health/colorado-hiker-...</td>\n",
       "      <td>Madeline Farber</td>\n",
       "      <td>Fox News Flash top headlines are here. Check o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  No. 10 Wisconsin cancels game with Purdue due ...   \n",
       "1                       Election 2020: Live Coverage   \n",
       "2  Beverly Hills spending $4.8M on 'election-prep...   \n",
       "3  NFL to consider 16-team playoff structure for ...   \n",
       "4  Colorado hiker with coronavirus-like symptoms ...   \n",
       "\n",
       "                            date  \\\n",
       "0  Tue, 03 Nov 2020 19:33:36 GMT   \n",
       "1  Tue, 03 Nov 2020 19:30:59 GMT   \n",
       "2  Tue, 03 Nov 2020 19:23:52 GMT   \n",
       "3  Tue, 03 Nov 2020 19:22:29 GMT   \n",
       "4  Tue, 03 Nov 2020 19:20:33 GMT   \n",
       "\n",
       "                                                link            author  \\\n",
       "0  https://www.foxnews.com/sports/no-10-wisconsin...              None   \n",
       "1  https://www.foxnews.com/politics/election-2020...              None   \n",
       "2  https://www.foxnews.com/us/beverly-hills-rodeo...  Danielle Wallace   \n",
       "3  https://www.foxnews.com/sports/nfl-16-team-pla...     Paulina Dedaj   \n",
       "4  https://www.foxnews.com/health/colorado-hiker-...   Madeline Farber   \n",
       "\n",
       "                                                text  \n",
       "0  Fox News Flash top headlines are here. Check o...  \n",
       "1                                                     \n",
       "2  Roughly 2,100 voters in Los Angeles County rec...  \n",
       "3  Fox News Flash top headlines are here. Check o...  \n",
       "4  Fox News Flash top headlines are here. Check o...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "fox_data={\"title\": titles2, \"date\": dates2,\"link\": links2, \"author\": authors2, \"text\": texts2}\n",
    "fox=pd.DataFrame(fox_data)\n",
    "fox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export results as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox.to_csv('./fox.csv', index=True)#export to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **feedparser** to parse the RSS feed of CBC news of top stories section. And check the result of one article for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Election day arrives in U.S. as polls open across country', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'https://www.cbc.ca/cmlink/rss-topstories', 'value': 'Election day arrives in U.S. as polls open across country'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.cbc.ca/news/world/us-election-day-2020-trump-biden-1.5787485?cmp=rss'}], 'link': 'https://www.cbc.ca/news/world/us-election-day-2020-trump-biden-1.5787485?cmp=rss', 'id': '1.5327704', 'guidislink': False, 'published': 'Sat, 19 Oct 2019 12:37:24 EDT', 'published_parsed': time.struct_time(tm_year=2019, tm_mon=10, tm_mday=19, tm_hour=16, tm_min=37, tm_sec=24, tm_wday=5, tm_yday=292, tm_isdst=0), 'authors': [{}], 'author': '', 'tags': [{'term': 'News', 'scheme': None, 'label': None}], 'summary': '<img alt=\"1229435769\" height=\"259\" src=\"https://i.cbc.ca/1.5787608.1604413470!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_460/1229435769.jpg\" title=\"ATLANTA, GA - NOVEMBER 03: A poll worker helps K. Maki (left) fill out a provisional ballot at Park Tavern polling station on November 3, 2020 in Atlanta, Georgia.  After a record-breaking early voting turnout, Americans head to the polls on the last day to cast their vote for incumbent U.S. President Donald Trump or Democratic nominee Joe Biden in the 2020 presidential election. (Photo by Jessica McGowan/Getty Images)\" width=\"460\" />                <p></p>', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'https://www.cbc.ca/cmlink/rss-topstories', 'value': '<img alt=\"1229435769\" height=\"259\" src=\"https://i.cbc.ca/1.5787608.1604413470!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_460/1229435769.jpg\" title=\"ATLANTA, GA - NOVEMBER 03: A poll worker helps K. Maki (left) fill out a provisional ballot at Park Tavern polling station on November 3, 2020 in Atlanta, Georgia.  After a record-breaking early voting turnout, Americans head to the polls on the last day to cast their vote for incumbent U.S. President Donald Trump or Democratic nominee Joe Biden in the 2020 presidential election. (Photo by Jessica McGowan/Getty Images)\" width=\"460\" />                <p></p>'}}\n"
     ]
    }
   ],
   "source": [
    "cbc_feed = feedparser.parse('https://rss.cbc.ca/lineup/topstories.xml')#feedparsing rss\n",
    "print(cbc_feed['entries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each article in parsed results, save its title, date, link, author, and full text. To get the full text of the article, we use **BeautifulSoup** to parse the html from its link, and select tags with the class of its main body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting metadata\n",
    "titles3 = []\n",
    "dates3 = []\n",
    "links3 = []\n",
    "authors3 = []\n",
    "texts3 = []\n",
    "for article in cbc_feed['entries']:\n",
    "    titles3.append(article['title'])\n",
    "    dates3.append(article['published'])\n",
    "    links3.append(article['link'])\n",
    "    html = rqst.urlopen(article['link'])\n",
    "    bs = BeautifulSoup(html, features='html.parser')\n",
    "    targets = bs.find(\"body\").select('.story')\n",
    "    if targets != []:\n",
    "        targets = targets[0].select('p')\n",
    "    text = ''\n",
    "    for target in targets:\n",
    "        text += target.text\n",
    "        text += ' '\n",
    "    texts3.append(text)\n",
    "    if 'author' in article:\n",
    "        authors3.append(article['author'])\n",
    "    else:\n",
    "        authors3.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframe is created by data saved previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Election day arrives in U.S. as polls open acr...</td>\n",
       "      <td>Sat, 19 Oct 2019 12:37:24 EDT</td>\n",
       "      <td>https://www.cbc.ca/news/world/us-election-day-...</td>\n",
       "      <td></td>\n",
       "      <td>The latest: After a campaign marked by rancour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canada's top public health doctor now recommen...</td>\n",
       "      <td>Tue, 3 Nov 2020 13:17:07 EST</td>\n",
       "      <td>https://www.cbc.ca/news/politics/three-layer-m...</td>\n",
       "      <td>Catharine Tunney</td>\n",
       "      <td>The Public Health Agency of Canada is now reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to follow U.S. election day coverage on CBC</td>\n",
       "      <td>Thu, 22 Oct 2020 20:36:51 EDT</td>\n",
       "      <td>https://www.cbc.ca/news/world/how-to-watch-us-...</td>\n",
       "      <td></td>\n",
       "      <td>This election day in the United States is goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trudeau, O'Toole vow to work with Trump, while...</td>\n",
       "      <td>Tue, 3 Nov 2020 13:48:42 EST</td>\n",
       "      <td>https://www.cbc.ca/news/politics/trudeau-otool...</td>\n",
       "      <td>John Paul Tasker</td>\n",
       "      <td>Prime Minister Justin Trudeau and Conservative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Muskoka cottage owner paid $64K to save it. ...</td>\n",
       "      <td>Tue, 3 Nov 2020 04:00:00 EST</td>\n",
       "      <td>https://www.cbc.ca/news/canada/toronto/muskoka...</td>\n",
       "      <td>John Lancaster</td>\n",
       "      <td>Liz Saunders ambles around the outside of her ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Election day arrives in U.S. as polls open acr...   \n",
       "1  Canada's top public health doctor now recommen...   \n",
       "2    How to follow U.S. election day coverage on CBC   \n",
       "3  Trudeau, O'Toole vow to work with Trump, while...   \n",
       "4  A Muskoka cottage owner paid $64K to save it. ...   \n",
       "\n",
       "                            date  \\\n",
       "0  Sat, 19 Oct 2019 12:37:24 EDT   \n",
       "1   Tue, 3 Nov 2020 13:17:07 EST   \n",
       "2  Thu, 22 Oct 2020 20:36:51 EDT   \n",
       "3   Tue, 3 Nov 2020 13:48:42 EST   \n",
       "4   Tue, 3 Nov 2020 04:00:00 EST   \n",
       "\n",
       "                                                link            author  \\\n",
       "0  https://www.cbc.ca/news/world/us-election-day-...                     \n",
       "1  https://www.cbc.ca/news/politics/three-layer-m...  Catharine Tunney   \n",
       "2  https://www.cbc.ca/news/world/how-to-watch-us-...                     \n",
       "3  https://www.cbc.ca/news/politics/trudeau-otool...  John Paul Tasker   \n",
       "4  https://www.cbc.ca/news/canada/toronto/muskoka...    John Lancaster   \n",
       "\n",
       "                                                text  \n",
       "0  The latest: After a campaign marked by rancour...  \n",
       "1  The Public Health Agency of Canada is now reco...  \n",
       "2  This election day in the United States is goin...  \n",
       "3  Prime Minister Justin Trudeau and Conservative...  \n",
       "4  Liz Saunders ambles around the outside of her ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "cbc_data={\"title\": titles3, \"date\": dates3,\"link\": links3, \"author\": authors3, \"text\": texts3}\n",
    "cbc=pd.DataFrame(cbc_data)\n",
    "cbc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export results as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc.to_csv('./cbc.csv', index=True)#export to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **feedparser** to parse the RSS feed of BBC news. And check the result of one article for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': \"UK terrorism threat level raised to 'severe'\", 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'http://feeds.bbci.co.uk/news/rss.xml', 'value': \"UK terrorism threat level raised to 'severe'\"}, 'summary': 'It means an attack is highly likely but there is no specific intelligence of an imminent incident.', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'http://feeds.bbci.co.uk/news/rss.xml', 'value': 'It means an attack is highly likely but there is no specific intelligence of an imminent incident.'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.bbc.co.uk/news/uk-54799377'}], 'link': 'https://www.bbc.co.uk/news/uk-54799377', 'id': 'https://www.bbc.co.uk/news/uk-54799377', 'guidislink': False, 'published': 'Tue, 03 Nov 2020 18:41:29 GMT', 'published_parsed': time.struct_time(tm_year=2020, tm_mon=11, tm_mday=3, tm_hour=18, tm_min=41, tm_sec=29, tm_wday=1, tm_yday=308, tm_isdst=0)}\n"
     ]
    }
   ],
   "source": [
    "bbc_feed = feedparser.parse('http://feeds.bbci.co.uk/news/rss.xml')#feedparsing rss\n",
    "print(bbc_feed['entries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each article in parsed results, save its title, date, link, author, and full text. To get the full text of the article, we use **BeautifulSoup** to parse the html from its link, and select tags with the class of its main body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting metadata\n",
    "titles4 = []\n",
    "dates4 = []\n",
    "links4 = []\n",
    "authors4 = []\n",
    "texts4 = []\n",
    "for article in bbc_feed['entries']:\n",
    "    titles4.append(article['title'])\n",
    "    dates4.append(article['published'])\n",
    "    links4.append(article['link'])\n",
    "    html = rqst.urlopen(article['link'])\n",
    "    bs = BeautifulSoup(html, features='html.parser')\n",
    "    targets = bs.select('.css-83cqas-RichTextContainer')\n",
    "    text = ''\n",
    "    for target in targets:\n",
    "        text += target.text\n",
    "        text += ' '\n",
    "    texts4.append(text)\n",
    "    if 'author' in article:\n",
    "        authors4.append(article['author'])\n",
    "    else:\n",
    "        authors4.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframe is created by data saved previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK terrorism threat level raised to 'severe'</td>\n",
       "      <td>Tue, 03 Nov 2020 18:41:29 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-54799377</td>\n",
       "      <td>None</td>\n",
       "      <td>.css-14iz86j-BoldText{font-weight:bold;}The UK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vienna shootings: Three men praised for helpin...</td>\n",
       "      <td>Tue, 03 Nov 2020 17:38:35 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-europe-54779882</td>\n",
       "      <td>None</td>\n",
       "      <td>.css-14iz86j-BoldText{font-weight:bold;}Three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Lewis and Currys PC World extend hours ah...</td>\n",
       "      <td>Tue, 03 Nov 2020 16:12:22 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/business-54795015</td>\n",
       "      <td>None</td>\n",
       "      <td>.css-14iz86j-BoldText{font-weight:bold;}John L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rape suspect Kadian Nelson urged to hand himse...</td>\n",
       "      <td>Tue, 03 Nov 2020 19:06:13 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-london-5...</td>\n",
       "      <td>None</td>\n",
       "      <td>.css-14iz86j-BoldText{font-weight:bold;}Police...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Town houses collapse leaves gaping hole in bui...</td>\n",
       "      <td>Tue, 03 Nov 2020 15:54:17 GMT</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-london-5...</td>\n",
       "      <td>None</td>\n",
       "      <td>.css-14iz86j-BoldText{font-weight:bold;}Two fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0       UK terrorism threat level raised to 'severe'   \n",
       "1  Vienna shootings: Three men praised for helpin...   \n",
       "2  John Lewis and Currys PC World extend hours ah...   \n",
       "3  Rape suspect Kadian Nelson urged to hand himse...   \n",
       "4  Town houses collapse leaves gaping hole in bui...   \n",
       "\n",
       "                            date  \\\n",
       "0  Tue, 03 Nov 2020 18:41:29 GMT   \n",
       "1  Tue, 03 Nov 2020 17:38:35 GMT   \n",
       "2  Tue, 03 Nov 2020 16:12:22 GMT   \n",
       "3  Tue, 03 Nov 2020 19:06:13 GMT   \n",
       "4  Tue, 03 Nov 2020 15:54:17 GMT   \n",
       "\n",
       "                                                link author  \\\n",
       "0             https://www.bbc.co.uk/news/uk-54799377   None   \n",
       "1   https://www.bbc.co.uk/news/world-europe-54779882   None   \n",
       "2       https://www.bbc.co.uk/news/business-54795015   None   \n",
       "3  https://www.bbc.co.uk/news/uk-england-london-5...   None   \n",
       "4  https://www.bbc.co.uk/news/uk-england-london-5...   None   \n",
       "\n",
       "                                                text  \n",
       "0  .css-14iz86j-BoldText{font-weight:bold;}The UK...  \n",
       "1  .css-14iz86j-BoldText{font-weight:bold;}Three ...  \n",
       "2  .css-14iz86j-BoldText{font-weight:bold;}John L...  \n",
       "3  .css-14iz86j-BoldText{font-weight:bold;}Police...  \n",
       "4  .css-14iz86j-BoldText{font-weight:bold;}Two fo...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "bbc_data={\"title\": titles4, \"date\": dates4,\"link\": links4, \"author\": authors4, \"text\": texts4}\n",
    "bbc=pd.DataFrame(bbc_data)\n",
    "bbc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export results as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc.to_csv('./bbc.csv', index=True)#export to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Text Processing for NY times dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will be using Bag of Words document representation like TF and TF-IDF and word embedding techniques like Word2Vec to extract features that can be used for scikit-learn models. The New York times data obtained above will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading, cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>‘Song Exploder’ and the Inexhaustible Hustle o...</td>\n",
       "      <td>Tue, 03 Nov 2020 16:50:28 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/hrishi...</td>\n",
       "      <td>Reggie Ugwu</td>\n",
       "      <td>Making something new is like climbing a mounta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I’m a Chess Expert. Here’s What ‘The Queen’s G...</td>\n",
       "      <td>Tue, 03 Nov 2020 17:09:24 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/televi...</td>\n",
       "      <td>Dylan Loeb McClain</td>\n",
       "      <td>This article contains spoilers for “The Queen’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>When a Dance Collective Was Like a Rock Band</td>\n",
       "      <td>Tue, 03 Nov 2020 13:54:35 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/dance/...</td>\n",
       "      <td>Gia Kourlas</td>\n",
       "      <td>In 1970, the Grand Union came into being, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A ‘Wicked’ Challenge and Other Tough Questions...</td>\n",
       "      <td>Tue, 03 Nov 2020 17:41:32 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/theater/ben...</td>\n",
       "      <td>Ben Brantley</td>\n",
       "      <td>I’m 15 years old and here is my question: When...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ian Bostridge on Schubert’s Hidden Depths</td>\n",
       "      <td>Tue, 03 Nov 2020 13:00:08 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/music/...</td>\n",
       "      <td>Ian Bostridge</td>\n",
       "      <td>I first got to know the 20 songs of Franz Schu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  ‘Song Exploder’ and the Inexhaustible Hustle o...   \n",
       "1           1  I’m a Chess Expert. Here’s What ‘The Queen’s G...   \n",
       "2           2       When a Dance Collective Was Like a Rock Band   \n",
       "3           3  A ‘Wicked’ Challenge and Other Tough Questions...   \n",
       "4           4          Ian Bostridge on Schubert’s Hidden Depths   \n",
       "\n",
       "                              date  \\\n",
       "0  Tue, 03 Nov 2020 16:50:28 +0000   \n",
       "1  Tue, 03 Nov 2020 17:09:24 +0000   \n",
       "2  Tue, 03 Nov 2020 13:54:35 +0000   \n",
       "3  Tue, 03 Nov 2020 17:41:32 +0000   \n",
       "4  Tue, 03 Nov 2020 13:00:08 +0000   \n",
       "\n",
       "                                                link              author  \\\n",
       "0  https://www.nytimes.com/2020/11/03/arts/hrishi...         Reggie Ugwu   \n",
       "1  https://www.nytimes.com/2020/11/03/arts/televi...  Dylan Loeb McClain   \n",
       "2  https://www.nytimes.com/2020/11/03/arts/dance/...         Gia Kourlas   \n",
       "3  https://www.nytimes.com/2020/11/03/theater/ben...        Ben Brantley   \n",
       "4  https://www.nytimes.com/2020/11/03/arts/music/...       Ian Bostridge   \n",
       "\n",
       "                                                text  \n",
       "0  Making something new is like climbing a mounta...  \n",
       "1  This article contains spoilers for “The Queen’...  \n",
       "2  In 1970, the Grand Union came into being, and ...  \n",
       "3  I’m 15 years old and here is my question: When...  \n",
       "4  I first got to know the 20 songs of Franz Schu...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the New York Times data\n",
    "df = pd.read_csv(\"ny.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title     0\n",
       "date      0\n",
       "link      0\n",
       "author    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True) # Since it is a duplicate of the dataframe indices\n",
    "\n",
    "#Check if there are any missing values\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of missing values is low, so we can drop the rows with nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing\n",
    "* We combine the text and title columns since they are likely to have similar words. In addition, combining them reduces the size of the vector representation of each article's text \n",
    "* we want to clean the data by removing numbers, punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i m a chess expert here s what the queen s gambit gets rightthis article contains spoilers for the queen s gambit in the netflix series the queen s gambit the character benny watts walks up to beth harmon the show s heroine at the start of the united states chess championship the location is a small auditorium on the campus of ohio university uttering an expletive benny gestures around the hall and complains about the conditions noting that the best players in the country are competing and yet the venue is second rate the chess boards and pieces are cheap plastic and the few spectators seem bored at best as a chess master who grew up in the era just after the one in which the series takes place and who wrote the chess column for the new york times for eight years i can attest to the scene s almost painful authenticity many tournaments of that era were played in odd and sometimes dingy locations even the u s championship was not immune the competition was not even held the exchange between beth played by anya taylor joy and benny thomas brodie sangster reflects an insider s knowledge of chess in the united states at the time that the show is set and is one of the many reasons that the series is one of the best and most successful screen adaptations of the game a short list that includes the film queen of katwe and searching for bobby fischer from the show s creators have also done a particularly good job at capturing and dramatizing the high tension of chess tournaments and the sometimes total obsessiveness that the game can inspire although it is played for comic effect there is more than a grain of truth to the scene in which harry beltik harry melling hauls a big box of chess books out of his car and starts passing them to beth in her living room only to discover that she has already read most of them and most skilled chess players have probably played at least a few games entirely in their heads by calling out the moves while speeding down a highway as beth and benny do over the decades it has become almost a running gag among chess fans to point out mistakes in onscreen portrayals of the game dan lucas one of the senior officials at the united states chess federation has kept an unofficial list for years among the most common transgressions boards that are oriented incorrectly there should always be a white square in the right corner incorrect arrangements of pieces such as reversing the kings and queens on their starting squares and characters who don t know how to move and handle the pieces working with two consultants garry kasparov the former world champion and bruce pandolfini a well known new york city chess coach the creators of the queen s gambit have avoided those errors pandolfini even has a cameo role as a kentucky tournament director the actors were trained on how to play and to move pieces like experts which is usually done with swift almost machine gun like movements taylor joy actually developed her own more fluid style as she explained in an interview with chess life magazine which was based on her training as a dancer in the series she scoops the pieces up and then softly flips them over the games portrayed in the series are not just realistic they are real based on actual competitions for example the match in which beth defeats harry for the kentucky state title was from a game in riga latvia in the last speed chess game in which she beats benny was played at the paris opera in and the game in which she faces the russian champion vasily borgov marcin dorocinski in the series finale was played in biel switzerland in despite the efforts to make the chess scenes believable there are still areas in which the series comes up short the most apparent is in how fast the players move during the tournaments as one tournament director tells beth before a competition in cincinnati each player has two hours to make moves which was and still is a standard time control for such games but in every match beth and her opponents make each of their moves after taking only a few seconds to think about them at such a tempo they would finish their games in minutes not hours the speed is understandable for filmmaking because watching players sit at a board for hours barely moving is not riveting but it is also not accurate nor is having competitors talk during some of the games other than offering a draw essentially agreeing that the match ends in a tie players do not speak to each other during matches it is not only considered bad sportsmanship it is also against the rules but several times as in beth s game against harry in episode in which she gloats near the end and in her game against a young russian prodigy in mexico city in episode beth and her opponents engage in verbal exchanges the dialogue makes the games more understandable and spices up the drama but once again it is not true to life though the queen s gambit is a work of fiction and the characters that appear in it never existed there are passing references to players who did among them the world champions josé raúl capablanca alexander alekhine mikhail botvinnik and boris spassky there is also a curious moment when harry compares beth to paul morphy an american who played that famous game at the paris opera in and who is widely considered the greatest player of the th century the comparison seems like a misdirection despite her self destructive tendencies beth does not resemble morphy she is closer to a female version of another champion bobby fischer that may not be accidental walter tevis who wrote the novel on which the series is based was a passionate and knowledgeable amateur player in making the protagonist a woman playing a game that had long been dominated by men and which continues to be today though no one knows the reason tevis may have been expressing a hope that one day there might be true equality of the sexes over the board fischer himself had been very dismissive of female players saying in a interview that they were terrible and that a likely reason was that they are not so smart making beth recall a female fischer may have been a sneaky and wonderful way to send up that assessment the parallels between beth and fischer are numerous minus her drug use which by the way would have only diminished not improved her play the queen s gambit covers a period from to that coincides with the peak of fischer s career which ran from when he won the u s championship at to when he won the world championship at and quit competing beth wins the u s championship that was the year fischer won his eighth and final american title after her adoptive mother dies in mexico city beth who is in her late teens finds herself living alone soon after fischer s older sister joan married and moved out his mother regina did too to pursue a medical degree that left fischer at living on his own fischer was somewhat antisocial and one dimensional there was little that he liked to talk about outside of chess beth is more likable a necessity for a leading character in a show but she has some similar traits she learns russian in order to be prepared to face the soviet players fischer taught himself russian so that he could read russian chess journals which were the best sources of information unlike the other top players in the show beth is able to make a living at chess even benny a past u s champion lives in a dingy basement fischer was a pioneer as a full time professional player in the united states kasparov has often said that it was fischer s demands for better playing conditions and larger prizes that professionalized the game when beth needs money to go to russia she asks the government to pay for the trip fischer s mother once picketed the white house to try to raise money for the united states chess team one of the reasons beth does not have enough money for the trip is because she has bought too many dresses fischer even though he was often scratching for money had his suits and shoes custom made finally beth and fischer have similar aggressive playing styles and when playing white and facing the sicilian defense they both play the same system the fischer sozin attack when it comes to how chess is portrayed onscreen chess players are a notoriously picky and unforgiving crowd we will pounce on any mistake though the queen s gambit has its flaws in the end the series is a clear winner \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#Combine title and text data\n",
    "df['title_text'] = df['title'] + df['text']\n",
    "\n",
    "def preprocessing(text):\n",
    "     # lowercase\n",
    "    text=text.lower()\n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['title_text'] = df['title_text'].apply(lambda x: preprocessing(x))\n",
    "print(df['title_text'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Separate data into training and testing, maybe do this step as a maybe when there are more data points\n",
    "df_train,df_test = train_test_split(df,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Document Representation (TF and TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides a TF-IDF vectorizer (TfidfVectorizer) that can create both TF and TF-IDF vector representations for text data. Note:\n",
    "* use_idf which if equal to true TF-IDF representation is used and TF is used otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for text processing using TF and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def text_processing(text, is_tfidf):\n",
    "    vectorizer = TfidfVectorizer(stop_words = 'english', \n",
    "                                 use_idf = is_tfidf, \n",
    "                                 max_features = 300, \n",
    "                                 ngram_range = (2,3)).fit(text)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Combine title and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the title of the article is related to the content of the article. So, in this context, combining the text and title before extracting features seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Representation based on TF (Term Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term frequency depends on the frequency of a word in the current article. Here, we create a TF vectorizer for the words in the article. We have limited the number of features to be 300 or less, used the common english stopwords provide by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>accident history</th>\n",
       "      <th>aghdashloo work</th>\n",
       "      <th>alike years</th>\n",
       "      <th>alike years come</th>\n",
       "      <th>alternative weekly</th>\n",
       "      <th>amber heard</th>\n",
       "      <th>american actors</th>\n",
       "      <th>...</th>\n",
       "      <th>work black artists</th>\n",
       "      <th>work mr</th>\n",
       "      <th>work ms</th>\n",
       "      <th>working dancers</th>\n",
       "      <th>worry dolls</th>\n",
       "      <th>year old</th>\n",
       "      <th>years later</th>\n",
       "      <th>years old</th>\n",
       "      <th>york city</th>\n",
       "      <th>york times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 03 Nov 2020 16:50:28 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/hrishi...</td>\n",
       "      <td>Reggie Ugwu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, 03 Nov 2020 17:41:32 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/theater/ben...</td>\n",
       "      <td>Ben Brantley</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue, 03 Nov 2020 13:00:08 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/music/...</td>\n",
       "      <td>Ian Bostridge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              date  \\\n",
       "0  Tue, 03 Nov 2020 16:50:28 +0000   \n",
       "1                              NaN   \n",
       "2                              NaN   \n",
       "3  Tue, 03 Nov 2020 17:41:32 +0000   \n",
       "4  Tue, 03 Nov 2020 13:00:08 +0000   \n",
       "\n",
       "                                                link         author  \\\n",
       "0  https://www.nytimes.com/2020/11/03/arts/hrishi...    Reggie Ugwu   \n",
       "1                                                NaN            NaN   \n",
       "2                                                NaN            NaN   \n",
       "3  https://www.nytimes.com/2020/11/03/theater/ben...   Ben Brantley   \n",
       "4  https://www.nytimes.com/2020/11/03/arts/music/...  Ian Bostridge   \n",
       "\n",
       "   accident history  aghdashloo work  alike years  alike years come  \\\n",
       "0               0.0              0.0          0.0               0.0   \n",
       "1               0.0              0.0          0.0               0.0   \n",
       "2               0.0              0.0          0.0               0.0   \n",
       "3               0.0              0.0          0.0               0.0   \n",
       "4               0.0              0.0          0.0               0.0   \n",
       "\n",
       "   alternative weekly  amber heard  american actors  ...  work black artists  \\\n",
       "0                 0.0          0.0              0.0  ...                 0.0   \n",
       "1                 0.0          0.0              0.0  ...                 0.0   \n",
       "2                 0.0          0.0              0.0  ...                 0.0   \n",
       "3                 0.0          0.0              0.0  ...                 0.0   \n",
       "4                 0.0          0.0              0.0  ...                 0.0   \n",
       "\n",
       "   work mr  work ms  working dancers  worry dolls  year old  years later  \\\n",
       "0      0.0      0.0              0.0          0.0       0.0          0.0   \n",
       "1      0.0      0.0              0.0          0.0       0.2          0.0   \n",
       "2      0.0      0.0              0.0          0.0       0.0          0.0   \n",
       "3      0.0      0.0              0.0          0.0       0.0          0.0   \n",
       "4      0.0      0.0              0.0          0.0       0.0          0.0   \n",
       "\n",
       "   years old  york city  york times  \n",
       "0        0.0        0.0         0.0  \n",
       "1        0.0        0.0         0.0  \n",
       "2        0.0        0.0         0.0  \n",
       "3        0.0        0.0         0.0  \n",
       "4        0.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform the train and test articles to vectors\n",
    "vectorizer = text_processing(df_train['title_text'], False)\n",
    "train_text_rep = vectorizer.transform(df_train['title_text'])\n",
    "test_text_rep = vectorizer.transform(df_test['title_text'])\n",
    "\n",
    "#Replace the article's text data (title and text) with their vector representations\n",
    "X_train_tf = pd.concat([df_train.drop(['title', 'text', 'title_text'], axis=1),\n",
    "           pd.DataFrame(data = train_text_rep.toarray(), columns = vectorizer.get_feature_names())], axis = 1)\n",
    "\n",
    "X_test_tf = pd.concat([df_test.drop(['title', 'text', 'title_text'], axis=1),\n",
    "           pd.DataFrame(data = test_text_rep.toarray(), columns = vectorizer.get_feature_names())], axis = 1)\n",
    "X_test_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Representation based on TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TF is problematic because words that are frequent but not necessarily useful (e.g. the) will have a high score. TF-IDF, combines TF and IDF, which measures the how rare a word is accross articles to solve the limitation. \n",
    "\n",
    "The settings for the model are the same as TF above expcept is_df which is now true to indicate this is an TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>accident history</th>\n",
       "      <th>aghdashloo work</th>\n",
       "      <th>alike years</th>\n",
       "      <th>alike years come</th>\n",
       "      <th>alternative weekly</th>\n",
       "      <th>amber heard</th>\n",
       "      <th>american actors</th>\n",
       "      <th>...</th>\n",
       "      <th>work black artists</th>\n",
       "      <th>work mr</th>\n",
       "      <th>work ms</th>\n",
       "      <th>working dancers</th>\n",
       "      <th>worry dolls</th>\n",
       "      <th>year old</th>\n",
       "      <th>years later</th>\n",
       "      <th>years old</th>\n",
       "      <th>york city</th>\n",
       "      <th>york times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 03 Nov 2020 16:50:28 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/hrishi...</td>\n",
       "      <td>Reggie Ugwu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, 03 Nov 2020 17:41:32 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/theater/ben...</td>\n",
       "      <td>Ben Brantley</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue, 03 Nov 2020 13:00:08 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/music/...</td>\n",
       "      <td>Ian Bostridge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              date  \\\n",
       "0  Tue, 03 Nov 2020 16:50:28 +0000   \n",
       "1                              NaN   \n",
       "2                              NaN   \n",
       "3  Tue, 03 Nov 2020 17:41:32 +0000   \n",
       "4  Tue, 03 Nov 2020 13:00:08 +0000   \n",
       "\n",
       "                                                link         author  \\\n",
       "0  https://www.nytimes.com/2020/11/03/arts/hrishi...    Reggie Ugwu   \n",
       "1                                                NaN            NaN   \n",
       "2                                                NaN            NaN   \n",
       "3  https://www.nytimes.com/2020/11/03/theater/ben...   Ben Brantley   \n",
       "4  https://www.nytimes.com/2020/11/03/arts/music/...  Ian Bostridge   \n",
       "\n",
       "   accident history  aghdashloo work  alike years  alike years come  \\\n",
       "0               0.0              0.0          0.0               0.0   \n",
       "1               0.0              0.0          0.0               0.0   \n",
       "2               0.0              0.0          0.0               0.0   \n",
       "3               0.0              0.0          0.0               0.0   \n",
       "4               0.0              0.0          0.0               0.0   \n",
       "\n",
       "   alternative weekly  amber heard  american actors  ...  work black artists  \\\n",
       "0                 0.0          0.0              0.0  ...                 0.0   \n",
       "1                 0.0          0.0              0.0  ...                 0.0   \n",
       "2                 0.0          0.0              0.0  ...                 0.0   \n",
       "3                 0.0          0.0              0.0  ...                 0.0   \n",
       "4                 0.0          0.0              0.0  ...                 0.0   \n",
       "\n",
       "   work mr  work ms  working dancers  worry dolls  year old  years later  \\\n",
       "0      0.0      0.0              0.0          0.0  0.000000          0.0   \n",
       "1      0.0      0.0              0.0          0.0  0.125558          0.0   \n",
       "2      0.0      0.0              0.0          0.0  0.000000          0.0   \n",
       "3      0.0      0.0              0.0          0.0  0.000000          0.0   \n",
       "4      0.0      0.0              0.0          0.0  0.000000          0.0   \n",
       "\n",
       "   years old  york city  york times  \n",
       "0        0.0        0.0         0.0  \n",
       "1        0.0        0.0         0.0  \n",
       "2        0.0        0.0         0.0  \n",
       "3        0.0        0.0         0.0  \n",
       "4        0.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform the train and test articles to vectors\n",
    "vectorizer = text_processing(df_train['title_text'], True)\n",
    "train_text_rep = vectorizer.transform(df_train['title_text'])\n",
    "test_text_rep = vectorizer.transform(df_test['title_text'])\n",
    "\n",
    "#Replace the article's text data (title and text) with their vector representations\n",
    "X_train_tfidf = pd.concat([df_train.drop(['title', 'text', 'title_text'], axis=1),\n",
    "           pd.DataFrame(data = train_text_rep.toarray(), columns = vectorizer.get_feature_names())], axis = 1)\n",
    "\n",
    "X_test_tfidf = pd.concat([df_test.drop(['title', 'text', 'title_text'], axis=1),\n",
    "           pd.DataFrame(data = test_text_rep.toarray(), columns = vectorizer.get_feature_names())], axis = 1)\n",
    "X_test_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2:  Separate title and text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In option 1, we combined article's title and text together because they are closely related. So, it might be impractical to vectorize them separately as we may end up with redundant columns. In general however, if  there are text features that are not related, one might want to vectorize them separately. Below, we show how the two features can be vectorized separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Representation based on TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>title_text</th>\n",
       "      <th>activism art</th>\n",
       "      <th>actor kids</th>\n",
       "      <th>actor kids right</th>\n",
       "      <th>actors say</th>\n",
       "      <th>agent suave</th>\n",
       "      <th>agent suave bond</th>\n",
       "      <th>...</th>\n",
       "      <th>white student</th>\n",
       "      <th>working dancers</th>\n",
       "      <th>workshop gallery</th>\n",
       "      <th>worry dolls</th>\n",
       "      <th>worth bingham</th>\n",
       "      <th>year old</th>\n",
       "      <th>years later</th>\n",
       "      <th>years old</th>\n",
       "      <th>york city</th>\n",
       "      <th>york times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 03 Nov 2020 16:50:28 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/hrishi...</td>\n",
       "      <td>Reggie Ugwu</td>\n",
       "      <td>song exploder and the inexhaustible hustle of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, 03 Nov 2020 17:41:32 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/theater/ben...</td>\n",
       "      <td>Ben Brantley</td>\n",
       "      <td>a wicked challenge and other tough questions f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue, 03 Nov 2020 13:00:08 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/music/...</td>\n",
       "      <td>Ian Bostridge</td>\n",
       "      <td>ian bostridge on schubert s hidden depthsi fir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              date  \\\n",
       "0  Tue, 03 Nov 2020 16:50:28 +0000   \n",
       "1                              NaN   \n",
       "2                              NaN   \n",
       "3  Tue, 03 Nov 2020 17:41:32 +0000   \n",
       "4  Tue, 03 Nov 2020 13:00:08 +0000   \n",
       "\n",
       "                                                link         author  \\\n",
       "0  https://www.nytimes.com/2020/11/03/arts/hrishi...    Reggie Ugwu   \n",
       "1                                                NaN            NaN   \n",
       "2                                                NaN            NaN   \n",
       "3  https://www.nytimes.com/2020/11/03/theater/ben...   Ben Brantley   \n",
       "4  https://www.nytimes.com/2020/11/03/arts/music/...  Ian Bostridge   \n",
       "\n",
       "                                          title_text  activism art  \\\n",
       "0   song exploder and the inexhaustible hustle of...           0.0   \n",
       "1                                                NaN           0.0   \n",
       "2                                                NaN           0.0   \n",
       "3  a wicked challenge and other tough questions f...           0.0   \n",
       "4  ian bostridge on schubert s hidden depthsi fir...           0.0   \n",
       "\n",
       "   actor kids  actor kids right  actors say  agent suave  agent suave bond  \\\n",
       "0         0.0               0.0         0.0          0.0               0.0   \n",
       "1         0.0               0.0         0.0          0.0               0.0   \n",
       "2         0.0               0.0         0.0          0.0               0.0   \n",
       "3         0.0               0.0         0.0          0.0               0.0   \n",
       "4         0.0               0.0         0.0          0.0               0.0   \n",
       "\n",
       "   ...  white student  working dancers  workshop gallery  worry dolls  \\\n",
       "0  ...            0.0              0.0               0.0          0.0   \n",
       "1  ...            0.0              0.0               0.0          0.0   \n",
       "2  ...            0.0              0.0               0.0          0.0   \n",
       "3  ...            0.0              0.0               0.0          0.0   \n",
       "4  ...            0.0              0.0               0.0          0.0   \n",
       "\n",
       "   worth bingham  year old  years later  years old  york city  york times  \n",
       "0            0.0       0.0          0.0        0.0        0.0         0.0  \n",
       "1            0.0       0.2          0.0        0.0        0.0         0.0  \n",
       "2            0.0       0.0          0.0        0.0        0.0         0.0  \n",
       "3            0.0       0.0          0.0        0.0        0.0         0.0  \n",
       "4            0.0       0.0          0.0        0.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 604 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On Training\n",
    "\n",
    "#Vectorize the title and text data separately\n",
    "title_vectorizer = text_processing(df_train['title'], False)\n",
    "title_rep = title_vectorizer.transform(df_train['title'])\n",
    "\n",
    "text_vectorizer = text_processing(df_train['text'], False)\n",
    "text_rep = text_vectorizer.transform(df_train['text'])\n",
    "\n",
    "X_train_tf = pd.concat([df_train.drop(['title', 'text'], axis=1),\n",
    "           pd.DataFrame(data = title_rep.toarray(), columns = title_vectorizer.get_feature_names()),\n",
    "           pd.DataFrame(data = text_rep.toarray(), columns = text_vectorizer.get_feature_names())], axis = 1)\n",
    "\n",
    "#On test data\n",
    "#transform the test data's title and text data separately\n",
    "title_rep = title_vectorizer.transform(df_test['title'])\n",
    "text_rep = text_vectorizer.transform(df_test['text'])\n",
    "\n",
    "X_test_tf = pd.concat([df_test.drop(['title', 'text'], axis=1),\n",
    "           pd.DataFrame(data = title_rep.toarray(), columns = title_vectorizer.get_feature_names()),\n",
    "           pd.DataFrame(data = text_rep.toarray(), columns = text_vectorizer.get_feature_names())], axis = 1)\n",
    "X_test_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Representation based on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Training\n",
    "\n",
    "title_vectorizer = text_processing(df_train['title'], True)\n",
    "title_rep = title_vectorizer.transform(df_train['title'])\n",
    "\n",
    "text_vectorizer = text_processing(df_train['text'], True)\n",
    "text_rep = text_vectorizer.transform(df_train['text'])\n",
    "\n",
    "X_train_tfidf = pd.concat([df_train.drop(['title', 'text'], axis=1),\n",
    "           pd.DataFrame(data = title_rep.toarray(), columns = title_vectorizer.get_feature_names()),\n",
    "           pd.DataFrame(data = text_rep.toarray(), columns = text_vectorizer.get_feature_names())], axis = 1)\n",
    "\n",
    "#On test data\n",
    "\n",
    "title_rep = title_vectorizer.transform(df_test['title'])\n",
    "text_rep = text_vectorizer.transform(df_test['text'])\n",
    "\n",
    "X_test_tfidf = pd.concat([df_test.drop(['title', 'text'], axis=1),\n",
    "           pd.DataFrame(data = title_rep.toarray(), columns = title_vectorizer.get_feature_names()),\n",
    "           pd.DataFrame(data = text_rep.toarray(), columns = text_vectorizer.get_feature_names())], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>title_text</th>\n",
       "      <th>activism art</th>\n",
       "      <th>actor kids</th>\n",
       "      <th>actor kids right</th>\n",
       "      <th>actors say</th>\n",
       "      <th>agent suave</th>\n",
       "      <th>agent suave bond</th>\n",
       "      <th>...</th>\n",
       "      <th>white student</th>\n",
       "      <th>working dancers</th>\n",
       "      <th>workshop gallery</th>\n",
       "      <th>worry dolls</th>\n",
       "      <th>worth bingham</th>\n",
       "      <th>year old</th>\n",
       "      <th>years later</th>\n",
       "      <th>years old</th>\n",
       "      <th>york city</th>\n",
       "      <th>york times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 03 Nov 2020 16:50:28 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/hrishi...</td>\n",
       "      <td>Reggie Ugwu</td>\n",
       "      <td>song exploder and the inexhaustible hustle of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, 03 Nov 2020 17:41:32 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/theater/ben...</td>\n",
       "      <td>Ben Brantley</td>\n",
       "      <td>a wicked challenge and other tough questions f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue, 03 Nov 2020 13:00:08 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/music/...</td>\n",
       "      <td>Ian Bostridge</td>\n",
       "      <td>ian bostridge on schubert s hidden depthsi fir...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              date  \\\n",
       "0  Tue, 03 Nov 2020 16:50:28 +0000   \n",
       "1                              NaN   \n",
       "2                              NaN   \n",
       "3  Tue, 03 Nov 2020 17:41:32 +0000   \n",
       "4  Tue, 03 Nov 2020 13:00:08 +0000   \n",
       "\n",
       "                                                link         author  \\\n",
       "0  https://www.nytimes.com/2020/11/03/arts/hrishi...    Reggie Ugwu   \n",
       "1                                                NaN            NaN   \n",
       "2                                                NaN            NaN   \n",
       "3  https://www.nytimes.com/2020/11/03/theater/ben...   Ben Brantley   \n",
       "4  https://www.nytimes.com/2020/11/03/arts/music/...  Ian Bostridge   \n",
       "\n",
       "                                          title_text  activism art  \\\n",
       "0   song exploder and the inexhaustible hustle of...           0.0   \n",
       "1                                                NaN           0.0   \n",
       "2                                                NaN           0.0   \n",
       "3  a wicked challenge and other tough questions f...           0.0   \n",
       "4  ian bostridge on schubert s hidden depthsi fir...           0.0   \n",
       "\n",
       "   actor kids  actor kids right  actors say  agent suave  agent suave bond  \\\n",
       "0         0.0               0.0         0.0          0.0               0.0   \n",
       "1         0.0               0.0         0.0          0.0               0.0   \n",
       "2         0.0               0.0         0.0          0.0               0.0   \n",
       "3         0.0               0.0         0.0          0.0               0.0   \n",
       "4         0.0               0.0         0.0          0.0               0.0   \n",
       "\n",
       "   ...  white student  working dancers  workshop gallery  worry dolls  \\\n",
       "0  ...            0.0              0.0               0.0          0.0   \n",
       "1  ...            0.0              0.0               0.0          0.0   \n",
       "2  ...            0.0              0.0               0.0          0.0   \n",
       "3  ...            0.0              0.0               0.0          0.0   \n",
       "4  ...            0.0              0.0               0.0          0.0   \n",
       "\n",
       "   worth bingham  year old  years later  years old  york city  york times  \n",
       "0            0.0  0.000000          0.0        0.0        0.0         0.0  \n",
       "1            0.0  0.125558          0.0        0.0        0.0         0.0  \n",
       "2            0.0  0.000000          0.0        0.0        0.0         0.0  \n",
       "3            0.0  0.000000          0.0        0.0        0.0         0.0  \n",
       "4            0.0  0.000000          0.0        0.0        0.0         0.0  \n",
       "\n",
       "[5 rows x 604 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Word embedding techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding techniques represents each word as a vector, in such a way that the context of the word is captured by that representation. That is, vector representation of words that are used in similar ways (e.g. mother, and father) are closer in the vector space.\n",
    "\n",
    "Some of the most popular word embedding techniques include: Word2Vec and GloVe\n",
    "\n",
    "In this section, the Word2Vec is used to get word embeddings for the New York Times articles (obtained above). Given the lack of a big dataset to train our own model, we will use Google Word2Vec pre-trained model. This model fits the context since it was trained on news articles with about 100 billion words. \n",
    "\n",
    "To get our text data vector representation, we will go though these 3 main steps:\n",
    "* Basic preprocessing of the data including tokenizing words, removing stop words and punctuation\n",
    "* Get word embeddings using the pre-trained model\n",
    "* Adapt word embeddings representation into data that can be used for modelling (e.g. classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the model and stopwords\n",
    "\n",
    "Here, the Word2Vec Google news pre-trained model is imported. It will be used to produce word embeddings for our news article dataset.\n",
    "The pre-trained model can be found here: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "\n",
    "In the data preprocessing stage, we want to remove stopwords from the data before using the model, so English stopwords are imported from nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\merci\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "# import stop words from the nltk library\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load Word2Vec pre-trained Google News model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary = True) \n",
    "\n",
    "# Convert the article's text into a list\n",
    "text_list = [text for text in df['title_text']]\n",
    "print(len(text_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing\n",
    "\n",
    "In this stage, we want to clean the data before we use the model. This includes:\n",
    "* Creating word tokens for each article\n",
    "* Basic data cleaning including removing stop words, punctuation, uppercases\n",
    "* Removing words that are not part of the pre-trained model vocabulary\n",
    "* Removing articles that are empty\n",
    "* Removing articles where none of its words is in the pre-trained model vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\merci\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chess', 'expert', 'queen', 'gambit', 'gets', 'article', 'contains', 'spoilers', 'queen', 'gambit', 'netflix', 'series', 'queen', 'gambit', 'character', 'benny', 'watts', 'walks', 'beth', 'harmon', 'show', 'heroine', 'start', 'united', 'states', 'chess', 'championship', 'location', 'small', 'auditorium', 'campus', 'ohio', 'university', 'uttering', 'expletive', 'benny', 'gestures', 'around', 'hall', 'complains', 'conditions', 'noting', 'best', 'players', 'country', 'competing', 'yet', 'venue', 'second', 'rate', 'chess', 'boards', 'pieces', 'cheap', 'plastic', 'spectators', 'seem', 'bored', 'best', 'chess', 'master', 'grew', 'era', 'one', 'series', 'takes', 'place', 'wrote', 'chess', 'column', 'new', 'york', 'times', 'eight', 'years', 'attest', 'scene', 'almost', 'painful', 'authenticity', 'many', 'tournaments', 'era', 'played', 'odd', 'sometimes', 'dingy', 'locations', 'even', 'u', 'championship', 'immune', 'competition', 'even', 'held', 'exchange', 'beth', 'played', 'anya', 'taylor', 'joy', 'benny', 'thomas', 'reflects', 'insider', 'knowledge', 'chess', 'united', 'states', 'time', 'show', 'set', 'one', 'many', 'reasons', 'series', 'one', 'best', 'successful', 'screen', 'adaptations', 'game', 'short', 'list', 'includes', 'film', 'queen', 'searching', 'bobby', 'fischer', 'show', 'creators', 'also', 'done', 'particularly', 'good', 'job', 'capturing', 'dramatizing', 'high', 'tension', 'chess', 'tournaments', 'sometimes', 'total', 'obsessiveness', 'game', 'inspire', 'although', 'played', 'comic', 'effect', 'grain', 'truth', 'scene', 'harry', 'harry', 'hauls', 'big', 'box', 'chess', 'books', 'car', 'starts', 'passing', 'beth', 'living', 'room', 'discover', 'already', 'read', 'skilled', 'chess', 'players', 'probably', 'played', 'least', 'games', 'entirely', 'heads', 'calling', 'moves', 'speeding', 'highway', 'beth', 'benny', 'decades', 'become', 'almost', 'running', 'gag', 'among', 'chess', 'fans', 'point', 'mistakes', 'onscreen', 'portrayals', 'game', 'dan', 'lucas', 'one', 'senior', 'officials', 'united', 'states', 'chess', 'federation', 'kept', 'unofficial', 'list', 'years', 'among', 'common', 'transgressions', 'boards', 'oriented', 'incorrectly', 'always', 'white', 'square', 'right', 'corner', 'incorrect', 'arrangements', 'pieces', 'reversing', 'kings', 'queens', 'starting', 'squares', 'characters', 'know', 'move', 'handle', 'pieces', 'working', 'two', 'consultants', 'former', 'world', 'champion', 'bruce', 'well', 'known', 'new', 'york', 'city', 'chess', 'coach', 'creators', 'queen', 'gambit', 'avoided', 'errors', 'even', 'cameo', 'role', 'kentucky', 'tournament', 'director', 'actors', 'trained', 'play', 'move', 'pieces', 'like', 'experts', 'usually', 'done', 'swift', 'almost', 'machine', 'gun', 'like', 'movements', 'taylor', 'joy', 'actually', 'developed', 'fluid', 'style', 'explained', 'interview', 'chess', 'life', 'magazine', 'based', 'training', 'dancer', 'series', 'scoops', 'pieces', 'softly', 'flips', 'games', 'portrayed', 'series', 'realistic', 'real', 'based', 'actual', 'competitions', 'example', 'match', 'beth', 'defeats', 'harry', 'kentucky', 'state', 'title', 'game', 'last', 'speed', 'chess', 'game', 'beats', 'benny', 'played', 'paris', 'opera', 'game', 'faces', 'russian', 'champion', 'series', 'finale', 'played', 'biel', 'switzerland', 'despite', 'efforts', 'make', 'chess', 'scenes', 'believable', 'still', 'areas', 'series', 'comes', 'short', 'apparent', 'fast', 'players', 'move', 'tournaments', 'one', 'tournament', 'director', 'tells', 'beth', 'competition', 'cincinnati', 'player', 'two', 'hours', 'make', 'moves', 'still', 'standard', 'time', 'control', 'games', 'every', 'match', 'beth', 'opponents', 'make', 'moves', 'taking', 'seconds', 'think', 'tempo', 'would', 'finish', 'games', 'minutes', 'hours', 'speed', 'understandable', 'filmmaking', 'watching', 'players', 'sit', 'board', 'hours', 'barely', 'moving', 'riveting', 'also', 'accurate', 'competitors', 'talk', 'games', 'offering', 'draw', 'essentially', 'agreeing', 'match', 'ends', 'tie', 'players', 'speak', 'matches', 'considered', 'bad', 'sportsmanship', 'also', 'rules', 'several', 'times', 'beth', 'game', 'harry', 'episode', 'gloats', 'near', 'end', 'game', 'young', 'russian', 'prodigy', 'mexico', 'city', 'episode', 'beth', 'opponents', 'engage', 'verbal', 'exchanges', 'dialogue', 'makes', 'games', 'understandable', 'spices', 'drama', 'true', 'life', 'though', 'queen', 'gambit', 'work', 'fiction', 'characters', 'appear', 'never', 'existed', 'passing', 'references', 'players', 'among', 'world', 'champions', 'alexander', 'boris', 'also', 'curious', 'moment', 'harry', 'compares', 'beth', 'paul', 'american', 'played', 'famous', 'game', 'paris', 'opera', 'widely', 'considered', 'greatest', 'player', 'th', 'century', 'comparison', 'seems', 'like', 'misdirection', 'despite', 'self', 'destructive', 'tendencies', 'beth', 'resemble', 'closer', 'female', 'version', 'another', 'champion', 'bobby', 'fischer', 'may', 'accidental', 'walter', 'wrote', 'novel', 'series', 'based', 'passionate', 'knowledgeable', 'amateur', 'player', 'making', 'protagonist', 'woman', 'playing', 'game', 'long', 'dominated', 'men', 'continues', 'today', 'though', 'one', 'knows', 'reason', 'may', 'expressing', 'hope', 'one', 'day', 'might', 'true', 'equality', 'sexes', 'board', 'fischer', 'dismissive', 'female', 'players', 'saying', 'interview', 'terrible', 'likely', 'reason', 'smart', 'making', 'beth', 'recall', 'female', 'fischer', 'may', 'sneaky', 'wonderful', 'way', 'send', 'assessment', 'parallels', 'beth', 'fischer', 'numerous', 'minus', 'drug', 'use', 'way', 'would', 'diminished', 'improved', 'play', 'queen', 'gambit', 'covers', 'period', 'coincides', 'peak', 'fischer', 'career', 'ran', 'u', 'championship', 'world', 'championship', 'quit', 'competing', 'beth', 'wins', 'u', 'championship', 'year', 'fischer', 'eighth', 'final', 'american', 'title', 'adoptive', 'mother', 'dies', 'mexico', 'city', 'beth', 'late', 'teens', 'finds', 'living', 'alone', 'soon', 'fischer', 'older', 'sister', 'joan', 'married', 'moved', 'mother', 'regina', 'pursue', 'medical', 'degree', 'left', 'fischer', 'living', 'fischer', 'somewhat', 'antisocial', 'one', 'dimensional', 'little', 'liked', 'talk', 'outside', 'chess', 'beth', 'likable', 'necessity', 'leading', 'character', 'show', 'similar', 'traits', 'learns', 'russian', 'order', 'prepared', 'face', 'soviet', 'players', 'fischer', 'taught', 'russian', 'could', 'read', 'russian', 'chess', 'journals', 'best', 'sources', 'information', 'unlike', 'top', 'players', 'show', 'beth', 'able', 'make', 'living', 'chess', 'even', 'benny', 'past', 'u', 'champion', 'lives', 'dingy', 'basement', 'fischer', 'pioneer', 'full', 'time', 'professional', 'player', 'united', 'states', 'often', 'said', 'fischer', 'demands', 'better', 'playing', 'conditions', 'larger', 'prizes', 'professionalized', 'game', 'beth', 'needs', 'money', 'go', 'russia', 'asks', 'government', 'pay', 'trip', 'fischer', 'mother', 'picketed', 'white', 'house', 'try', 'raise', 'money', 'united', 'states', 'chess', 'team', 'one', 'reasons', 'beth', 'enough', 'money', 'trip', 'bought', 'many', 'dresses', 'fischer', 'even', 'though', 'often', 'scratching', 'money', 'suits', 'shoes', 'custom', 'made', 'finally', 'beth', 'fischer', 'similar', 'aggressive', 'playing', 'styles', 'playing', 'white', 'facing', 'defense', 'play', 'system', 'fischer', 'attack', 'comes', 'chess', 'portrayed', 'onscreen', 'chess', 'players', 'notoriously', 'picky', 'unforgiving', 'crowd', 'pounce', 'mistake', 'though', 'queen', 'gambit', 'flaws', 'end', 'series', 'clear', 'winner']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#FUnction for basic preprocessing\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    #Get word tokens for the article\n",
    "    article = word_tokenize(text)\n",
    "    \n",
    "    #remove stop words\n",
    "    article = [word for word in article if word not in stop_words]\n",
    "    \n",
    "    #remove punctuation\n",
    "    article = [word for word in article if word.isalpha()] \n",
    "    \n",
    "    #remove words that are not in the pre-trained model vocabulary\n",
    "    article = [word for word in article if word in model.vocab]\n",
    "    \n",
    "    return article\n",
    "\n",
    "collection = [preprocess(text) for text in text_list]\n",
    "\n",
    "#Remove any empty articles\n",
    "collection = [article for article in collection if len(article) > 0]\n",
    "\n",
    "# Want to remove all articles with none of its words in the pretrained model's vocabulary\n",
    "collection = [article for article in collection if not all(word not in model.vocab for word in article)]\n",
    "print(collection[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data cleaning, an article tokens look like the above. Now, we can pass the tokenized articles to the model to get word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the pre-trained model to vectorize data\n",
    "\n",
    "Passing the tokenized data, we get word embeddings for each article. Note that each word is represented by a 300 long vector. So, each article has a (number of words in article by 300) matrix representation. \n",
    "\n",
    "However, this matrix representation is not practical if we are going to use the resulting representation for scikit-learn algorithms like classification. In other words, we need to represent each article with a vector instead of a matrix. To do that, We average over the rows of the matrix (i.e average over the words in the article) to get a 300 long vector representation of the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of getting word embeddings for one article using the pretrained model and converting that into a vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article size (Number of words):  757\n",
      "Dimensions of returned vector representation:  (757, 300)\n",
      "Final article vector representation:  (300,)\n",
      "[ 0.01933521  0.03753862  0.02249091  0.07384218 -0.00304275  0.00455796\n",
      "  0.03144605 -0.07511539  0.05584898  0.07820767 -0.01551456 -0.10441145\n",
      " -0.04442851  0.01821963 -0.0786284   0.0711761   0.05042451  0.11170877\n",
      "  0.02418499 -0.06758834  0.00220837  0.05266898  0.01790958 -0.01257178\n",
      "  0.00155603 -0.04016721 -0.10146177  0.06132949 -0.00831238 -0.0232123\n",
      " -0.03476984  0.00704002 -0.00741802  0.01187331  0.03841127 -0.01465935\n",
      "  0.01790204  0.04132473  0.05244576  0.05568149  0.09817482 -0.04886817\n",
      "  0.10871352  0.02379193 -0.01191496 -0.05154021 -0.03097785 -0.01147875\n",
      "  0.00709169  0.04319341 -0.04366703  0.05001208 -0.03585338 -0.03495815\n",
      " -0.01109524  0.00600169 -0.02844731 -0.10010839  0.01369905 -0.06960253\n",
      " -0.00233859  0.06745585 -0.06478704 -0.07270085 -0.00467693  0.00583099\n",
      " -0.02882861  0.05726865 -0.01905065  0.06747171  0.04988686  0.02336246\n",
      "  0.03749971  0.012882   -0.13096163 -0.03701877  0.03702106  0.03732139\n",
      "  0.03539129  0.04972678  0.00694513 -0.00331122  0.03900895 -0.0063271\n",
      "  0.00760731 -0.02572809 -0.08237672  0.10578558  0.04953543  0.02804013\n",
      "  0.0477393  -0.02512119 -0.10146865 -0.03818188 -0.01227728 -0.02863577\n",
      "  0.02721637 -0.0034927   0.00933157 -0.0376812  -0.0447241   0.00548609\n",
      "  0.02006172 -0.00632742 -0.0214738  -0.02901333 -0.01092519 -0.01496052\n",
      "  0.02984876 -0.04511803 -0.00331938  0.00332129 -0.00099812 -0.00687197\n",
      "  0.0988633   0.01364603  0.0229937  -0.03973211  0.07465533  0.00207986\n",
      " -0.07525928 -0.00171062 -0.01078272  0.02757969 -0.0170998  -0.0561198\n",
      " -0.04552433 -0.00846201 -0.02226278  0.02575671 -0.0562039  -0.10152396\n",
      " -0.03764323  0.01861317 -0.04132316 -0.024      -0.01683305  0.02455926\n",
      " -0.03228628  0.0380156   0.04985115 -0.08347926  0.02312586  0.0036545\n",
      "  0.02182486  0.08948818 -0.01384637 -0.01023772 -0.05184675 -0.02946047\n",
      "  0.07170792  0.02643859 -0.07721111  0.02669789 -0.04911933 -0.0497981\n",
      " -0.03730926 -0.05603429 -0.04322875 -0.04850964  0.00833776  0.06264198\n",
      "  0.06532178 -0.00446804 -0.01456114 -0.0751024   0.08401135 -0.07469077\n",
      " -0.01514021  0.02262248 -0.09249116 -0.02995193  0.01406023 -0.06060884\n",
      " -0.00500852 -0.02103548  0.0560991  -0.0812456   0.00110057 -0.00603951\n",
      " -0.03206287 -0.06416684  0.00592798  0.00199418 -0.00717936  0.02275998\n",
      " -0.00178496  0.01240379  0.05421067  0.03788851  0.05184279  0.0150918\n",
      "  0.01081087 -0.00438094 -0.02103691  0.0398601  -0.02090482 -0.00302219\n",
      " -0.06843577 -0.06927321 -0.0118877   0.04518105 -0.02239561 -0.01252181\n",
      "  0.0074236  -0.07726076 -0.00589805 -0.00868491 -0.03871123 -0.00990184\n",
      " -0.00478434  0.07686216 -0.03699555  0.02834316 -0.09702384 -0.01600674\n",
      "  0.04844057 -0.00356977 -0.09189688  0.00145926 -0.01270475 -0.00660423\n",
      "  0.01904095  0.00192771  0.02705721 -0.03354916  0.03322157 -0.00020628\n",
      "  0.01957268 -0.02791922  0.01241272 -0.03444126  0.00279238  0.0292403\n",
      "  0.06877334 -0.01385519  0.04122992 -0.08012744  0.0766414   0.00746951\n",
      "  0.0630141  -0.011058    0.02132514 -0.09698087 -0.02065216  0.03428218\n",
      " -0.01211742  0.05201984  0.00142445 -0.04433503  0.02184411  0.06159157\n",
      "  0.04893595  0.0704023   0.02117705 -0.03507091  0.00128173 -0.00620901\n",
      " -0.04445713 -0.01822946  0.00138899  0.01593336 -0.00337742  0.00057964\n",
      "  0.0361557   0.1298464  -0.01436281 -0.01694614 -0.06188352  0.00259166\n",
      " -0.00382873  0.07111283  0.01596075  0.03352933  0.06884726 -0.04748372\n",
      " -0.05769198 -0.06034691 -0.06774282  0.02607958  0.00303913 -0.02780659\n",
      "  0.02365158  0.02889972  0.0012952  -0.03789612 -0.0849377   0.0135699\n",
      "  0.01901717  0.05005496 -0.08164146  0.00543082 -0.08825413 -0.01743547\n",
      " -0.01896129 -0.02910635  0.01673363 -0.03973909  0.00465288  0.02119328]\n"
     ]
    }
   ],
   "source": [
    "#Example of the vector representation returned by the model\n",
    "example_embedding = model[collection[1]]\n",
    "print(\"Article size (Number of words): \", len(collection[1]))\n",
    "print(\"Dimensions of returned vector representation: \", np.array(example_embedding).shape)\n",
    "\n",
    "#To get a one dimensional vector representation of the article, average over the words to get a 300 by 1 vector representation\n",
    "final_representation = np.mean(example_embedding, axis=0)\n",
    "print(\"Final article vector representation: \", final_representation.shape)\n",
    "print(final_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform similar steps as in the above example to get the final document representation for the whole collection of articles of the dataset. This representation is then merged with the original dataframe to create a dataset that can be used for scikit-learn algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 03 Nov 2020 16:50:28 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/hrishi...</td>\n",
       "      <td>Reggie Ugwu</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>-0.013325</td>\n",
       "      <td>0.068121</td>\n",
       "      <td>-0.029784</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.040280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053279</td>\n",
       "      <td>0.023308</td>\n",
       "      <td>-0.111168</td>\n",
       "      <td>-0.006335</td>\n",
       "      <td>-0.038804</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>-0.042574</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue, 03 Nov 2020 17:09:24 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/televi...</td>\n",
       "      <td>Dylan Loeb McClain</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>0.037539</td>\n",
       "      <td>0.022491</td>\n",
       "      <td>0.073842</td>\n",
       "      <td>-0.003043</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.031446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081641</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>-0.088254</td>\n",
       "      <td>-0.017435</td>\n",
       "      <td>-0.018961</td>\n",
       "      <td>-0.029106</td>\n",
       "      <td>0.016734</td>\n",
       "      <td>-0.039739</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.021193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, 03 Nov 2020 13:54:35 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/dance/...</td>\n",
       "      <td>Gia Kourlas</td>\n",
       "      <td>0.039026</td>\n",
       "      <td>0.022501</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.090727</td>\n",
       "      <td>-0.036886</td>\n",
       "      <td>-0.017872</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088283</td>\n",
       "      <td>0.028951</td>\n",
       "      <td>-0.091134</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>-0.055262</td>\n",
       "      <td>-0.051101</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>-0.047479</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>-0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, 03 Nov 2020 17:41:32 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/theater/ben...</td>\n",
       "      <td>Ben Brantley</td>\n",
       "      <td>0.044677</td>\n",
       "      <td>0.038605</td>\n",
       "      <td>0.018023</td>\n",
       "      <td>0.091937</td>\n",
       "      <td>-0.052442</td>\n",
       "      <td>-0.007660</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084238</td>\n",
       "      <td>0.033683</td>\n",
       "      <td>-0.095721</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>-0.041119</td>\n",
       "      <td>-0.021825</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>-0.038794</td>\n",
       "      <td>0.034905</td>\n",
       "      <td>0.004407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue, 03 Nov 2020 13:00:08 +0000</td>\n",
       "      <td>https://www.nytimes.com/2020/11/03/arts/music/...</td>\n",
       "      <td>Ian Bostridge</td>\n",
       "      <td>0.086072</td>\n",
       "      <td>0.045585</td>\n",
       "      <td>-0.010598</td>\n",
       "      <td>0.069083</td>\n",
       "      <td>-0.045031</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.065773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068940</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>-0.112651</td>\n",
       "      <td>-0.022302</td>\n",
       "      <td>-0.062983</td>\n",
       "      <td>-0.033652</td>\n",
       "      <td>0.032777</td>\n",
       "      <td>-0.040017</td>\n",
       "      <td>0.031406</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              date  \\\n",
       "0  Tue, 03 Nov 2020 16:50:28 +0000   \n",
       "1  Tue, 03 Nov 2020 17:09:24 +0000   \n",
       "2  Tue, 03 Nov 2020 13:54:35 +0000   \n",
       "3  Tue, 03 Nov 2020 17:41:32 +0000   \n",
       "4  Tue, 03 Nov 2020 13:00:08 +0000   \n",
       "\n",
       "                                                link              author  \\\n",
       "0  https://www.nytimes.com/2020/11/03/arts/hrishi...         Reggie Ugwu   \n",
       "1  https://www.nytimes.com/2020/11/03/arts/televi...  Dylan Loeb McClain   \n",
       "2  https://www.nytimes.com/2020/11/03/arts/dance/...         Gia Kourlas   \n",
       "3  https://www.nytimes.com/2020/11/03/theater/ben...        Ben Brantley   \n",
       "4  https://www.nytimes.com/2020/11/03/arts/music/...       Ian Bostridge   \n",
       "\n",
       "          0         1         2         3         4         5         6  ...  \\\n",
       "0  0.041694  0.019194 -0.013325  0.068121 -0.029784  0.007827  0.040280  ...   \n",
       "1  0.019335  0.037539  0.022491  0.073842 -0.003043  0.004558  0.031446  ...   \n",
       "2  0.039026  0.022501  0.007078  0.090727 -0.036886 -0.017872  0.040199  ...   \n",
       "3  0.044677  0.038605  0.018023  0.091937 -0.052442 -0.007660  0.049574  ...   \n",
       "4  0.086072  0.045585 -0.010598  0.069083 -0.045031  0.021492  0.065773  ...   \n",
       "\n",
       "        290       291       292       293       294       295       296  \\\n",
       "0 -0.053279  0.023308 -0.111168 -0.006335 -0.038804 -0.040099  0.033622   \n",
       "1 -0.081641  0.005431 -0.088254 -0.017435 -0.018961 -0.029106  0.016734   \n",
       "2 -0.088283  0.028951 -0.091134  0.005467 -0.055262 -0.051101  0.057514   \n",
       "3 -0.084238  0.033683 -0.095721  0.008553 -0.041119 -0.021825  0.031232   \n",
       "4 -0.068940  0.005981 -0.112651 -0.022302 -0.062983 -0.033652  0.032777   \n",
       "\n",
       "        297       298       299  \n",
       "0 -0.042574  0.021526  0.001228  \n",
       "1 -0.039739  0.004653  0.021193  \n",
       "2 -0.047479  0.017819 -0.000300  \n",
       "3 -0.038794  0.034905  0.004407  \n",
       "4 -0.040017  0.031406  0.023256  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "# Do the same step as above for all articles to get the final dataset that can be used for modelling\n",
    "for article in collection:\n",
    "    #average over the word vectors of the current article to get its final vector representation\n",
    "    X.append(np.mean(model[article], axis=0))\n",
    "\n",
    "#Replace the title and text features with their vector representations\n",
    "X = pd.concat([df.drop(['title', 'text', 'title_text'], axis=1),\n",
    "           pd.DataFrame(data = X)], axis = 1)\n",
    "X.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
